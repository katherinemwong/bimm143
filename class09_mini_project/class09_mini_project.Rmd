---
title: "Unsupervised Mini Project"
author: "Katherine Wong (A16162648)"
date: "10/26/2021"
output:
  github_document:
  pdf_document: default
  html_document: default
---
# Preparing the data

# Save your input data file into your Project directory
```{r}
fna.data <- "WisconsinCancer.csv"
#Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data, row.names=1)
#wisc.df
```
# Create a new data.frame that omits first column (pathologist diagnosis)

```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
# Create diagnosis vector for later 
diagnosis <- as.factor(wisc.df$diagnosis)
```

#Exploratory dataset

> Q1. How many observations are in this dataset?

```{r}
dim(wisc.data)
length(diagnosis)
```
There are 569 samples or observations in wisc.data and diagnosis. 

> Q2. How many of the observations have a malignant diagnosis?

```{r}
table(diagnosis)
```
212 of 560 observations have a malignant diagnosis.

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
length(grep("_mean", colnames(wisc.data)))
```
There are 10 variables/features in the data that are suffixed with _mean

# Principal Component Analysis

Performing PCA
```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

# Perform PCA on wisc.data by completing the following code

```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
# Look at summary of results
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

The proportion of the original variance captured by PC1 is 0.4427 or 44.27%. 

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3. PC1: 44.27%, PC2: 18.97%, PC3: 9.39%. Together this accounts for more than 72.64% of the original variance in the data. 

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7. 7 PCs cumulatively describe 91.01% of the original variance in the data.

# Interpreting PCA results

```{r}
biplot(wisc.pr)
```
> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot is extremely messy and cluttered. It is difficult to understand because so many labels are overlapping each other. Hard to make out trends.

# Generate a more standard scatter plot of each observation along principal components 1 and 2

```{r}
# Scatter plot observations by components 1 and 2
plot( wisc.pr$x[ ,1:2], col = diagnosis, 
     xlab = "PC1", ylab = "PC2")
```

```{r}
plot(wisc.pr$x[, c(1,3)], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")

```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

I notice that PC2 scores are higher than PC3. Both plots are still high in terms of PC1. the dots higher on the PC1 scale are black (benign) while the ones lower on the PC1 scale are red (malignant).

# Create a data.frame for ggplot

```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
```

# Load the ggplot2 package

```{r}
library(ggplot2)
```

# Make a scatter plot colored by diagnosis

```{r}
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

# Variance explained

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var/29 #29 total pc

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```
```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
## ggplot based graph
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

# Communicating PCA results

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean",1]
```

For the first principal component, the component of the loading vector for concave.points_mean is -0.2608538. 

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
var <- summary(wisc.pr)
var$importance[3, ]
```

Minimum 5 PCs, cumulatively they account for 84.73% of the variance of the data. 4 PCs is too little because it only accounts for 79.24% of the variance of the data.

# Hierarchical clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
#calculate Euclidean distances between all pairs of observations in new scaled dataset and assign the result to data.dist
data.dist <- dist(data.scaled)

#create a hierarchical clustering model using complete linkage. Manually specify the method argument to hclust() and assign the results to wisc.hclust.

wisc.hclust <- hclust(data.dist)
plot(wisc.hclust)
abline(h = 19, col="red", lty=2)
```
> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

At height 19.

Cut the tree into 4 groups

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
```

Compare to diagnosis results
```{r}
table(wisc.hclust.clusters, diagnosis)
```
> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?
2 is a better cluster vs diagnoses match because it is closer to the actual diagnosis numbers! (356 B and 212 M)

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=2)
table(wisc.hclust.clusters, diagnosis)
```


> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.
Ward.D2 because I like spherical and compact clusters. And identifying a top group is helpful for me to understand!

# Optional: K-means clustering

```{r}
wisc.km <- kmeans(data.scaled, centers= 2, nstart= 20)
table(wisc.km$cluster, diagnosis)
```

> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?

k-means does not separate the two diagnoses too well. Compared to hclust, hclust is more accurate because its B and M numbers are closer to the original diagnoses numbers (356 B and 212 M). k-means numbers are a bit too low. 

```{r}
table(wisc.hclust.clusters, wisc.km$cluster)
```

# Combining methods

We take the results of our PCA analysis and cluster in this space 'wisc.pr$x'

```{r}
summary(wisc.pr)
```

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3]), 
                         method="ward.D2")
```

Plot my dendrogram
```{r}
plot(wisc.pr.hclust)
abline(h=60, col="red")
```

Cut the tree into k=2 groups
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```
```{r}
table(grps, diagnosis)

```

>Q15. How well does the newly created model with four clusters separate out the two diagnoses?

The newly created model with four clusters does not separate out the two diagnoses too well. The numbers are not close to the actual diagnoses numbers (356 B and 212 M)


# 6. Sensitivity/Specificity
**Accuracy** What proportion did we get correct if we call cluster 1 M and cluster 2 B

```{r}
(333 + 179)/nrow(wisc.data)
```
**Sensitivity** refers to a test’s ability to correctly detect ill patients who do have the condition. In our example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

```{r}
179/(179 + 33)
```

**Specificity** relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).

```{r}
333/(333+24)
```


> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
table(wisc.km$cluster, diagnosis)
```

Hierarchical clustering model did so much better. It is closer to the actual diagnoses numbers (356 B and 212 M).


> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Hierarchical clustering:
Specificity = 0.9328
```{r}
333/(333+24)
```

Sensitivity = 0.8443
```{r}
179/(179 + 33)
```
K-means = 
```{r}
table(wisc.km$cluster, diagnosis)
```
Specificity = 0.8255
```{r}
175/(175+37)
```

Sensitivity = 0.9608
```{r}
343/(343 + 14)
```
Hierarchical clustering did best in specificity. K-means did better in sensitivity.

# Prediction

Here we read some new data and use our PCA model to examine whether they most closely resemble M or B patients from our original dataset

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

Plot onto our pca model
```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```
> Q18. Which of these new patients should we prioritize for follow up based on your results?

benign = black
malignant = red

Most likely patient 2 because it's surrounded by multiple benign patients, and it's important to follow up with those who are diagnosed with malignant tumors.



